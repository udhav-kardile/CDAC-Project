# delivery_analyzer.py
import boto3
import pandas as pd
import os

class DeliveryAnalyzer:
    def __init__(self, precomputed_risk_data_path=None):
        """
        Initializes the DeliveryAnalyzer.
        In a real scenario for your project, this would represent insights derived from your
        Spark SQL analysis. For the Flask app, we can either:
        1. Load a pre-computed CSV/JSON summary of risk zones (generated by your Spark job).
        2. Use hardcoded rules for demonstration.
        """
        self.risk_data = {}
        # Ensure dummy_rules is always initialized
        self._set_dummy_rules() # <--- CALL THIS FIRST

        if precomputed_risk_data_path and os.path.exists(precomputed_risk_data_path):
            try:
                # Example: Load a CSV with Region, Seller, Risk_Level
                # The CSV should have 'Region', 'Seller' and 'Risk_Level' columns
                df = pd.read_csv(precomputed_risk_data_path)
                # Ensure 'Region' and 'Seller' columns exist and are correct
                if 'Region' in df.columns and 'Seller' in df.columns and 'Risk_Level' in df.columns:
                    # Convert to string and title case for consistency if needed
                    df['Region'] = df['Region'].astype(str).str.strip().str.title()
                    df['Seller'] = df['Seller'].astype(str).str.strip()
                    self.risk_data = df.set_index(['Region', 'Seller'])['Risk_Level'].to_dict()
                    print(f"Loaded pre-computed risk data from: {precomputed_risk_data_path}")
                else:
                    print(f"Warning: CSV at {precomputed_risk_data_path} is missing expected columns (Region, Seller, Risk_Level). Using dummy rules.")
            except Exception as e:
                print(f"Error loading pre-computed risk data: {e}. Using dummy rules.")
        else:
            print("Precomputed risk data path not provided or file not found. Using dummy rules (already set).")


    def _set_dummy_rules(self):
        """Defines dummy rules for demonstration if no pre-computed data is loaded."""
        # Attach dummy_rules to self directly
        self.dummy_rules = {
            ("Mumbai", "SellerX"): "High Risk - Frequent delays due to congestion",
            ("Delhi", "SellerY"): "Medium Risk - Occasional delays during peak hours",
            ("Kolkata", "SellerZ"): "Low Risk - Efficient logistics",
            ("Chennai", "SellerA"): "Medium Risk - Port-related delays",
            ("Bengaluru", "SellerB"): "High Risk - Last-mile delivery challenges",
        }

    def analyze_delivery_risk(self, region: str, seller_id: str):
        """
        Analyzes the delivery risk for a given region and seller.
        This function would ideally look up in pre-computed results from your Spark SQL analysis,
        or apply simple logic based on those insights.
        """
        region = region.strip().title() # Normalize region input (e.g., "mumbai" -> "Mumbai")
        seller_id = seller_id.strip()

        # Try to get from loaded data first, then fall back to dummy rules
        # Use .get() method on dictionaries to safely retrieve values
        risk_level = self.risk_data.get((region, seller_id), self.dummy_rules.get((region, seller_id), "Unknown Risk - No specific data available"))

        return {
            "region": region,
            "seller_id": seller_id,
            "risk_level": risk_level,
            "notes": "Analysis based on historical patterns and insights (e.g., from Spark SQL)."
        }

# This block is for testing the class directly (optional)
if __name__ == "__main__":
    # Create a dummy 'data' directory if it doesn't exist
    if not os.path.exists('data'):
        os.makedirs('data')

    # Create a dummy CSV for testing the file loading part
    dummy_df = pd.DataFrame({
        'Region': ['Mumbai', 'Delhi', 'Pune', 'Mumbai'],
        'Seller': ['Seller1', 'Seller2', 'Seller3', 'SellerX'], # Added SellerX to Mumbai to test override
        'Risk_Level': ['High', 'Medium', 'Low', 'Critical'] # Example of data overriding dummy rule
    })
    dummy_df.to_csv('data/delivery_risk_zones.csv', index=False)
    print("Created dummy data/delivery_risk_zones.csv")

    print("\n--- Testing DeliveryAnalyzer with pre-computed data ---")
    analyzer_with_data = DeliveryAnalyzer(precomputed_risk_data_path="data/delivery_risk_zones.csv")
    print(analyzer_with_data.analyze_delivery_risk("Mumbai", "Seller1")) # Should be 'High' from CSV
    print(analyzer_with_data.analyze_delivery_risk("Pune", "Seller3"))   # Should be 'Low' from CSV
    print(analyzer_with_data.analyze_delivery_risk("Mumbai", "SellerX")) # Should be 'Critical' from CSV, overriding dummy rule

    print("\n--- Testing DeliveryAnalyzer with only dummy rules (no CSV path or file not found) ---")
    analyzer_no_data = DeliveryAnalyzer() # No path given, so uses dummy rules
    print(analyzer_no_data.analyze_delivery_risk("mumbai", "SellerX")) # Should use dummy rule: "High Risk - Frequent delays..."
    print(analyzer_no_data.analyze_delivery_risk("Delhi", "SellerY"))   # Should use dummy rule: "Medium Risk - Occasional delays..."
    print(analyzer_no_data.analyze_delivery_risk("Hyderabad", "Seller10")) # Will be "Unknown Risk"

    # Clean up dummy data folder (optional, good practice for automated tests)
    if os.path.exists('data/delivery_risk_zones.csv'):
        os.remove('data/delivery_risk_zones.csv')
    if os.path.exists('data') and not os.listdir('data'):
        os.rmdir('data')